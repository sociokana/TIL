# Replication Controller

Controller란?
- 쿠버네티스를 움직이는 두뇌와도 같은 것들. 
- 쿠버네티스 오브젝트를 모니터하고 이에 따라 적절한 반응을 하는 프로세스들을 가리킴. 

Replica 란? 
- 왜 필요한가?
	- 가용성을 위해, 동시에 여러 개의 pod이나 인스턴스를 가동할 필요가 있을 수 있음. 
	- replication controller는 하나의 pod의 다수의 인스턴스를 쿠버네티스 클러스터로 가동함으로써 가용성을 확보할 수 있음. 
	- 만약 하나의 pod만이 있었다면 문제가 생겼을 때 그 pod을 빠르게 동일한 것으로 자동적으로 대체함으로써 가용성을 확보함. 
- Load Balancing & Scaling 
	- 로드밸런싱을 위해 팟을 동시에 띄우거나 혹은 node를 추가로 deploy해서 여러 개의 pod에 대한 로드밸런싱을 할 수가 있음. 
- Replica Set과의 차이점
	- 같은 목적이지만 같지는 않음. Replica Set이 새로운 방식. 
- 어떻게 만드는가?
-
```
apiVersion: v1
kind: ReplicationController
metadata: 
	name: rc-test
	labels:
		app: app-test 
spec: 
	template: #이 부분 아래에 apiVersion 및 kind를 제외한 POD에 대한 정보가 들어가야 함
		metadata:
			name: hoge
			labels:
				app: hoge 
		spec:
			containers:
				- name: nginx-test
				  image: nginx
	replicas: 숫자


```

``kubectl create -f rc-definition.yml``
``kubectl get replicationcontroller``

replica set의 경우:  apiVersion, kind, selector의 존재가 다름 
```
apiVersion: apps/v1
kind: ReplicationSet
metadata: 
	name: rs-test
	labels:
		app: app-test 
spec: 
	template: #이 부분 아래에 apiVersion 및 kind를 제외한 POD에 대한 정보가 들어가야 함
		metadata:
			name: hoge
			labels:
				app: hoge 
				labelsample: labeltest1
		spec:
			containers:
				- name: nginx-test
				  image: nginx
	replicas: 숫자
	selector: #팟의 어떤 부분이 레플리카셋에 해당하는지 지정. RS는 RC와는 달리 RS로 생성되지 않은 Pod에 대해서도 레플리카를 만들 수가 있기 때문에. 
		matchLabels:
			labelsample: labeltest1
```
``kubectl create -f rs-definition.yml``
``kubectl get replicaset``

Labels and Selector
- 이를테면 동시에 몇 개의 pod가 항상 띄워져 있는지를 보장하기 위해. 
- 어떤 Pod을 모니터할지 Replica Set이 어떻게 알까? 레이블을 달아두는 게 편한 이유. 

Scaling (수동으로)
- yaml 파일 속의 ``replicas: `` 의 숫자를 늘리고, ``kubectl replace -f replicaset.yaml``을 해줌. 
- kubectl scale --replicas=새 숫자 -f replicaset.yaml 을 지정해줌. 
- kubectl scale --replicas=새 숫자 replicaset replicaset-name
- 아래 두 경우에는 원래 yaml 파일의 숫자는 변하지 않음. 

commands:
``kubectl scale replicaset replicaset-test --replicase=숫자``


# Deployment

Rollout and versioning 

``kubectl rollout status deployment/이름``
``kubectl rollout history deployment/이름

### deployment 전략 
- recreate: 한번에 모든 걸 내려버리고 업그레이드하려고 함. 다운타임이 발생. 
- rolling update: 하나씩 내리고 올리는 전략이 있음. 
- deployment 파일에서 image 부분에서 이름:버전명을 기록.
- ``kubectl apply -f yaml파일
- ``kubectl set image deployment/이름 nginx=nginx:1.9.1 `` 과 같은 식으로도 설정 가능. 이 경우에는 yaml파일이 업데이트되지는 않음.
- 업데이트할 경우 쿠버네티스는 새로운 replicaset을 자동으로 만들고 그 안에 새로운 컨테이너들을 deploy한 후 기존에 있던 replicaset의 컨테이너들을 하나하나 내림.


rollback

``kubectl rollout undo deployment/이름 

# networking 

- 하나의 node에는 ip가 할당되어 있고, pod에도 내부적으로 ip 주소가 하나씩 할당되어 있음. 
- 쿠버네티스가 처음 설정될 때 내부 프라이빗 인터넷을 설정하고 이 노드에 들어가는 팟에 각각 ip를 부여함. (그러나 다른 pod을 이 ip주소를 써서 접속하는 건 좋은 발상이 아님. pod이 다시만들어질 때 이 ip 주소들이 변할 것이므로. )
- 복수의 node가 존재하고 각각에 ip주소가 존재할 때는? 클러스터링을 할 필요가 있음. 자동적으로 이런 네트워크 이슈를 쿠버네티스가 설정해주지는 않음. 
- 다음과 같은 설정을 기본적으로 해줄 필요가 있음. 
	- 모든 컨테이너/팟은 NAT를 거치지 않고 서로와 통신할 필요가 있다.
	- 모든 노드는 NAT를 거치지 않고 모든 컨테이너와 통신할 수 있으며 그 반대도 가능해야 한다. 
- 모든 걸 직접 설정할 필요는 없음. cisco 제품이나, nsx-t, flannel, cilium 등을 사용할 수 있음. 